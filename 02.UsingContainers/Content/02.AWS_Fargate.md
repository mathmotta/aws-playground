# Hosting Containers in EC2: The bigger picture

Two different layers to manage when hosting containers: EC2 instances for hosting, as well as the containers that you place on top of those instances(cluster).

## 1. Get started

We need to provision, configure and scale a cluster of EC2 instances. We put the instances in subnets inside of our VPC across avalability zones. For provisioning, we need to choose the EC2 instance type, the AMI, and provide any other EC2 config that may be needed(e.g. user data) for bootstrapping

Since EC2 will host docker containers, we need to make sure installing docker is part of the bootstrapping process.

Also we need to make sure tha these instances are continually patched, updated and evaluated for security.

## 2. Setup and Configure EC2 auto scaling

Auto scaling provides new EC2 instances when the demand on the containers goes up, and terminate as containers are stopped and need less compute infrastructure.

After all is setup and functioning, we can run containers on top of this cluster(group of EC2 instances).

Each EC2 instance will most likely have multiple container instances running inside it, especially as we scale up the number of containers we need.

## 3. ECS (Elastic Container Service)

Service to run and manage containers, (more in depth later). We do not interact with the host directly.

## 4. Amazon Cloud Watch

Monitor to ensure cluster is scaling properly and we can tweak as needed to optimize cluster resources.

## 5. AWS Fargate

Serverless compute engine and hosting option for container-based workloads. Allows to host containers on top of fully managed compute platform, so no provisioning infrastructure, no setting up cluster scaling, and no server management over time. It abstracts all of it away from us.

With AWS Fargate, we only care about what containers need to run:

1. What image to use
2. How much memory and VCPU
3. Network
4. IAM permissions that are needed